{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ナイーブベイズ演習　迷惑メール自動振り分け"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット\n",
    "https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "- ダウンロード\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00228/\n",
    "smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "messages = pd.read_table('smsspamcollection/SMSSpamCollection',\n",
    "                         names=['label','message'])\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "label      5572 non-null object\n",
      "message    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "messages.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理\n",
    "ラベルをhamを0に、spamを1のバイナリに変換しましょう。\n",
    "sklearnを使用して、学習を行う場合、バイナリ(1 or 0)に変換しておく必要があるためです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['label'] = messages['label'].map( {'spam': 1, 'ham': 0} ).astype(int)\n",
    "print(messages.shape)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of wordsの実装\n",
    "まずはサンプルから"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec_sample = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_messages = ['Thank you for calling.',\n",
    "            'Thank you for your inquiry',\n",
    "            'Thanks for keeping in touch.',\n",
    "            'Thanks for getting in touch with me?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec_sample.fit(sample_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = count_vec_sample.transform(sample_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "        [0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bag of wordsをデータセットに適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "count_vec =  CountVectorizer(analyzer='word', \n",
    "                                binary=False, \n",
    "                                decode_error='strict',\n",
    "                                # dtype=<class 'numpy.int64'>, \n",
    "                                encoding='utf-8', \n",
    "                                input='content',\n",
    "                                lowercase=True, \n",
    "                                max_df=1.0, \n",
    "                                max_features=None, \n",
    "                                min_df=1,\n",
    "                                ngram_range=(1, 1), \n",
    "                                preprocessor=None, \n",
    "                                stop_words=None,\n",
    "                                strip_accents=None, \n",
    "                                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                                tokenizer=None, \n",
    "                                vocabulary=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.fit(messages['message'])\n",
    "\n",
    "#単語毎の出現回数を表示\n",
    "#count_vec.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットを分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179,) (1393,) (4179,) (1393,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['message'],\n",
    "                                                    messages['label'],\n",
    "                                                    random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_train、X_testをBag of wordsに置き換える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer()#fitする前にCountVectorizer()を初期化する。\n",
    "count_vector.fit(X_train)\n",
    "X_train = count_vector.transform(X_train)\n",
    "#count_vector.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_testをBags of wordsに変換する際に新しくCountVectorizerクラスのインスタンスを\\n使用しないのは、X_trainと同じ条件、つまり同じ単語と番号の組み合わせで管理するためです。\\n新しくfitさせてしまうと、同じ単語でも異なる番号で組み合わされてしまいます。'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = count_vector.transform(X_test)\n",
    "\n",
    "'''X_testをBags of wordsに変換する際に新しくCountVectorizerクラスのインスタンスを\n",
    "使用しないのは、X_trainと同じ条件、つまり同じ単語と番号の組み合わせで管理するためです。\n",
    "新しくfitさせてしまうと、同じ単語でも異なる番号で組み合わされてしまいます。'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル実装・学習\n",
    "今回のモデルは、MultinomialNBを使用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価\n",
    "最後に評価を行いましょう。テストデータを使用して、以下の４つの評価を行ってください。\n",
    ">0. Accuracy\n",
    ">0. Precision\n",
    ">0. Recall\n",
    ">0. F1 Score(f-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.989\n",
      "test Precision: 0.972\n",
      "test Recall   : 0.941\n",
      "test F1       : 0.956\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      1208\n",
      "          1       0.97      0.94      0.96       185\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1393\n",
      "\n",
      "\n",
      "**Confusion_Matrix**\n",
      "[[1203    5]\n",
      " [  11  174]]\n",
      "[[True_Positive , False_Negative] \n",
      " [False_Positive , True_Negative]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "print('Accuracy score: {:.3f}'.format(accuracy_score(y_test,y_pred)))\n",
    "print('test Precision: {:.3f}'.format(precision_score(y_test, y_pred)))\n",
    "print('test Recall   : {:.3f}'.format(recall_score(y_test, y_pred)))\n",
    "print('test F1       : {:.3f}'.format(f1_score(y_test, y_pred)))\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "print()\n",
    "print('**Confusion_Matrix**')\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print(CM)\n",
    "print('[[True_Positive , False_Negative] \\n [False_Positive , True_Negative]]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Blue'>Precision（適合率）</font>と <font color='Red'>Recall（再現率）</font>について\n",
    "- 両者はトレードオフ。\n",
    "- したがって、タスクに応じてどちらを重視するか判断する。\n",
    "\n",
    "### １. 見逃しが多くても、より正確な予測を求めたいタスクの場合：\n",
    "- <font color='Blue'>**Precision重視**</font>\n",
    "\n",
    "    >* スパムメール振り分けタスクなど\n",
    "      - よりによって重要なメールがスパムと誤まって判定されて開封できなかったらきつい。\n",
    "       **→ ＜False_Positive(FP)は困る＞**\n",
    "      - 逆に、スパム判定が見逃されてメールBOXに入ってきたスパムメールがたまにあっても、削除すればいい。\n",
    "       **→ ＜False_Negative(FN)はまぁまぁ許容する＞**\n",
    "    >* したがって、多少の見逃しは許容するから、スパム判定時の精度にはこだわりたい。\n",
    "    <font color='Blue'>***→Precision ＝ TP / (TP + FP) が1に近づくほどうれしい。***</font>\n",
    "    \n",
    "### ２. 誤判定が多くても、より見逃しを少なくしたいタスクの場合：\n",
    "- <font color='Red'>**Recall重視**</font>\n",
    "\n",
    "    >* 病気の診断、重要機材の部品メンテナンスタスクなど\n",
    "      - 重大な病気や重要部品の欠陥の判定が見逃されるのはきつい。\n",
    "        **→ ＜False_Negative(FN)は困る＞**\n",
    "      - 逆に、見逃しを防ぐあまり的中率がやや下がって病気の誤診があっても、再検査すればいいし、交換した部品が誤判定により実は正常だったとしても事故発生よりはマシ。\n",
    "          **→ ＜False_Positiveはまぁまぁ許容する＞**\n",
    "    >* したがって、多少の誤判定は許容するから、見逃さない分類器にこだわりたい。\n",
    "    <font color='Red'>***→Recall ＝ TP / (TP + FN) が１に近づくほどうれしい。***</font>\n",
    "\n",
    "### <font color='Green'>F値</font>について\n",
    "上記のトレードオフを踏まえて、実際に分類器を比較するのに使われるのが<font color='Green'>F値（F-measure)</font>。\n",
    ">* **PrecisionとRecallの調和平均**\n",
    "    - <font color='Blue'>Precision : P</font>\n",
    "    - <font color='Red'>Recall : R</font>\n",
    "    - <font color='Green'>**F値 = 2 / (1/P)+(1/R)**</font>\n",
    "    \n",
    ">* <font color='Blue'>P</font>と<font color='Red'>R</font>のバランスが良ければ<font color='Green'>F値</font>が高くなる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
